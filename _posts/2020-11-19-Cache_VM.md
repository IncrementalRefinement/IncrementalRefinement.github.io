# cache & virtual memory

## cache

### 设计cache的原因

1. 大多数情况下程序仅对内存的一小部分进行读写.

   Programs access only a small portion of the full address space at any instant of time.

2. 一段在先前被读写的内存在之后被再次读写的概率非常大. (2. 是 1. 的延伸,其实是同一点)

3. 直接对内存读写所需的时间比对cache进行读写长得多得多(inside a room --> pluto)

综合以上几点, 将读写的部分内存暂存到cache中, 当cache中有所需段的内存时就直接对cache进行读写, 如果进行写操作的话再将写后的结果存入内存中, 但如果cache中没有所需的部分内存, 那么就需要将该对应的内存读入cache.

cache作为一个中介/buffer, 由于1.2.两种情况的普遍性, 可以大大优化程序的读写操作

### cache的设计方式

既然已经认识到cache的作用是用于暂时代替真正的内存/下一级的cache被进行读写, 那么cache应该能对所要读写的内存中的数据地址在cache中进行查找/读取/写入. 

我们将原先的32bit地址进行分段处理&cache的各种设计方法的根本目的还是为了更好实现cache的中介特性

需要注意的是cache在设计好之后整个cache的size以及具体的实现方法已经被定死了, 所以IOT等位的分段也是被硬件本身限制了

IOT分段的本质就是为了在整个cache中用不同的方式进行分set&在set中查找, 需要注意的是IOT中的Offset和Index并没有被编入cache, IO的这一部分选择是通过硬件(mux等)进行实现的(implicitly implmented by hardware).

### 地址的TIO三段解释 & associative

cache的assocaitive考虑其实可以类比于hash, 通过将地址中的一段作为hash值(Index), 将整个cache分为许多set, 每个set中有block用于存储一段内存, 而每个block中存储了规定数量的byte

Tag 段用于在set中判断和找寻该tag对应的block

Index 段用于搜索set

Offset用于在blcok找寻对应的byte

direct map (set num = 1, 将整个Cache看做一个set，没有Index段) --->  set associative (in between) ---> fully associative (set num = block num, 没有block段)
上述的变化就是不断增大associativity & 增加index段长度的过程

但需要注意的是输入cache的地址就是原先直接对于内存进行读写的32bit地址, 所以TIO三段的长度之和也应该一直是32, 具体TIO的分段方式是由cache本身的硬件构造决定的, 不能单纯看作一种另外的取址方式

### 其他知识点

AMAT, 多级cache串联, Total bits in cache ....

## virtual memory

### virtual memory 的设计原因

1. 将不同的进程的内存进行分隔和保护
2. 通过虚拟内存, 可将内存暂存到硬盘中, 突破实际物理内存大小的限制
3. 也可以通过公用一段物理内存节省内存 & 在不同进程中进行交互

### virtual memory 的设计方式

1. 将虚拟内存和物理内存分隔为大小相等的一个个pages, physical pages 的存储可以是离散的.

2. 每个进程在自己的内存中维护一段内存作为page table, page table可将虚拟内存映射为物理内存

   page table 将VPN(virtual page number)映射为PPN(physical page number), 同时也要维护该段VPN的valid(是否已由内存读取到内存中)

3. VPN和PPN的长度通常并不相同, 但是每一个虚拟内存地址VPN段之外的offset段与实际物理内存地址的offset段是相同的(也就是虚拟内存和物理内存中的page大小是相同的), 所以映射只需要将VPN段替换为PPN段即可(valid的情况下)

4. page table存储在内存中, 我们同样可以构造一个对应于page table条目的cache来加快page table中entry的读写, 这也就有了Translation Lookaside Buffer (TLB), 这个cache的设计就不再赘述

5. 由于VM的地址长度通常远大于PM, 所以table中很多entry的所占内存被浪费了, 所以可以设计Hierarchical Page Table, 进行多次映射, 减少物理内存消耗

### 考虑到VM之后的内存地址操作

1. 首先根据VM在TLB中查询entry, 如果缓存中没有, 会从PM中读取TLB的entry并写入缓存

2. 根据虚拟内存和内存表的条目进行映射, 获得物理内存

   这一步结束后已经获得物理内存的地址, 之后的操作是对于物理内存的cache进行操作

3. 对于存储物理内存内容的cache进行查询, 如果valid就从cache直接读取物理内存

4. 如果cache并没有缓存, 那么从内存中读取相应的内容并记入cache



1) 2)两步获得的是物理内存地址, 3) 4) 两步获得的是对应物理内存地址中的内容, 每部分的cache也对应这一过程的所需内容



## ps

 以上内容力求提纲挈领, 大方向能把握住, 省略了很多cache & VM的细节以及注意点(比如对chache进行write以及write时cache中没有缓存对应内容,valid, dirty位的处理等等), 可自行学习cs61c或相关课程获取该方面知识点











