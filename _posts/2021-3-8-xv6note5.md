# <center>xv_6 note(5): concurrency control</center>

cuccrency control是操作系统的一个重要主题：一方面os可以说是最先遇到并尝试解决concurrency问题的软件；另一方面，os也提供了接口为其上的软件提供mechanism来达成concurrency control。本文主要基于手册的6、7两章以及6.s081上相关的实验，这篇笔记完成之后就只剩filesystem的部分 XDDDDD

## Source code

### spinlock

选取spinlock.c &spinlock.h中我认为有意思/关键的代码如下:

```c
struct spinlock {
  uint locked;       // Is the lock held?

  // For debugging:
  char *name;        // Name of lock.
  struct cpu *cpu;   // The cpu holding the lock.
};
```

一个spinlock结构的定义，locked、name分别表示锁是否被获取以及锁的名字，而cpu则代表当前占有获取锁的cpu

```c
void
acquire(struct spinlock *lk)
{
  push_off(); // disable interrupts to avoid deadlock.
  if(holding(lk))
    panic("acquire");

  // On RISC-V, sync_lock_test_and_set turns into an atomic swap:
  //   a5 = 1
  //   s1 = &lk->locked
  //   amoswap.w.aq a5, a5, (s1)
  while(__sync_lock_test_and_set(&lk->locked, 1) != 0)
    ;

  // Tell the C compiler and the processor to not move loads or stores
  // past this point, to ensure that the critical section's memory
  // references happen strictly after the lock is acquired.
  // On RISC-V, this emits a fence instruction.
  __sync_synchronize();

  // Record info about lock acquisition for holding() and debugging.
  lk->cpu = mycpu();
}
```

获取锁:

1. 如果holding为true，表示当前cpu已经获取了锁，重复获取就panic(说实话我还是不知道panic的具体作用是啥，惭愧)
2. __sync_lock_test_and_set 就是risc-v指令集架构为实现锁提供的H/W support，这个操作是个原子操作，如果仅仅依靠软件支持，就会出现获取锁--》获取锁的锁--》获取锁的锁的锁这种无限递归的情况，无法根本上解决问题
3. __sync_synchronize()，编译器为了优化CPU执行指令可能会reording指令，这种优化可能会导致在并行情况下产生错误，这个调用的作用就是就是告诉编译器以及H/W不要在锁这种关键部分耍小聪明进行优化
4. push_off()的作用留到后面和pop_off()一起解释

```c
void
release(struct spinlock *lk)
{
  if(!holding(lk))
    panic("release");

  lk->cpu = 0;
  __sync_synchronize();
  __sync_lock_release(&lk->locked);
  pop_off();
}
```

释放锁，几个函数的大致作用和性质和获取中类似，反推一下即可，不再赘述

```c
void
push_off(void)
{
  int old = intr_get();

  intr_off();
  if(mycpu()->noff == 0)
    mycpu()->intena = old;
  mycpu()->noff += 1;
}

void
pop_off(void)
{
  struct cpu *c = mycpu();
  if(intr_get())
    panic("pop_off - interruptible");
  if(c->noff < 1)
    panic("pop_off");
  c->noff -= 1;
  if(c->noff == 0 && c->intena)
    intr_on();
}
```

```c
struct cpu {
  struct proc *proc;          // The process running on this cpu, or null.
  struct context context;     // swtch() here to enter scheduler().
  int noff;                   // Depth of push_off() nesting.
  int intena;                 // Were interrupts enabled before push_off()?
};
```

我们再来看之前跳过的 push_off 和 pop_off 这两个函数，并分析他们的作用：

1. push_off/pop_off的作用类似于intr_off()/intr_on()用于关闭/打开一个cpu上的interrupt，事实上这两个函数的包裹下最终也是调用intr_off()/intr_on()，在获取/释放锁的过程中调用这两个函数的目的是为了防止在获取锁的过程中的interrupt导致的线程切换导致死锁(这一部分其实也并不特别清楚，留到QA环节)
2. push_off和pop_off是相互match的，也就是说一个push_off需要一个pop_off来undo，两个push_off需要两个pop_off来undo....cpu结构中的noff记录的就是push_off的层数，而intena就是表示当前cpu能否被interrupt

### sleeplock

为了解决spinlock中busy waiting浪费时间片的情况，引入了sleep lock，有点mutex/CV的感觉，下面选取 sleeplock.h&sleep.c中部分代码:

```c
struct sleeplock {
  uint locked;       // Is the lock held?
  struct spinlock lk; // spinlock protecting this sleep lock
  
  // For debugging:
  char *name;        // Name of lock.
  int pid;           // Process holding lock
};
```

```c
void
acquiresleep(struct sleeplock *lk)
{
  acquire(&lk->lk);
  while (lk->locked) {
    sleep(lk, &lk->lk);
  }
  lk->locked = 1;
  lk->pid = myproc()->pid;
  release(&lk->lk);
}

void
releasesleep(struct sleeplock *lk)
{
  acquire(&lk->lk);
  lk->locked = 0;
  lk->pid = 0;
  wakeup(lk);
  release(&lk->lk);
}
```

我们可以看到sleeplock内部实现借助了spinlock来实现的，spinlock用于保护sleeplock中的locked变量，在获取和释放sleeplock的时候首先要获取spinlock，而关键就在于理解wakeup，sleep这两个函数的作用，我们下面就来看这两个函数(在proc.c中)

```c
void
sleep(void *chan, struct spinlock *lk)
{
  struct proc *p = myproc();
  
  if(lk != &p->lock){  //DOC: sleeplock0
    acquire(&p->lock);  //DOC: sleeplock1
    release(lk);
  }

  // Go to sleep.
  p->chan = chan;
  p->state = SLEEPING;

  sched();

  // Tidy up.
  p->chan = 0;

  // Reacquire original lock.
  if(lk != &p->lock){
    release(&p->lock);
    acquire(lk);
  }
}

// Wake up all processes sleeping on chan.
// Must be called without any p->lock.
void
wakeup(void *chan)
{
  struct proc *p;

  for(p = proc; p < &proc[NPROC]; p++) {
    acquire(&p->lock);
    if(p->state == SLEEPING && p->chan == chan) {
      p->state = RUNNABLE;
    }
    release(&p->lock);
  }
}
```

1. 每个proc结构都有一个属于自己的自旋锁，在sleep过程中首先获取当前进程的锁，从而保证只有自己能修改当前进程的pcb，结合下面的wakeup函数看，这样做也可以保证不会错过对当前进程的wakeup
2. 结合acquire看，sleep中的chan的入参就是一个spinlock，将当前进程的pcb的chan设置为尝试获取的spinlock，从而实现将进程与spinlock绑定
3. sleep完场上述操作之后调用sched()，将控制权交给进程调度器，sched函数也很有意思，下面会讲到
4. wakeup会遍历内核中的proc[]数组，将所有pcb的chan为指定sleeplock的状态都设置为RUNNABLE，这是一种比较稚嫩的实现手法(暂时当然我也说不出成熟的做法, XD)，可能会导致被唤醒的proc再次进入沉睡，从而引入内核态用户态切换的overhead，但这样相比于只唤醒一个而言能在一定程度上避免starvation

### swtch & sched

```c
void
yield(void)
{
  struct proc *p = myproc();
  acquire(&p->lock);
  p->state = RUNNABLE;
  sched();
  release(&p->lock);
}
```

调用yield，主动将当前线程挂起，将线程状态标为RUNNABLE，并调用sched切换到内核的进程调度线程scheduler

```c
void
sched(void)
{
  int intena;
  struct proc *p = myproc();

  if(!holding(&p->lock))
    panic("sched p->lock");
  if(mycpu()->noff != 1)
    panic("sched locks");
  if(p->state == RUNNING)
    panic("sched running");
  if(intr_get())
    panic("sched interruptible");

  intena = mycpu()->intena;
  swtch(&p->context, &mycpu()->context);
  mycpu()->intena = intena;
}

void
scheduler(void)
{
  struct proc *p;
  struct cpu *c = mycpu();
  
  c->proc = 0;
  for(;;){
    // Avoid deadlock by ensuring that devices can interrupt.
    intr_on();
    
    int found = 0;
    for(p = proc; p < &proc[NPROC]; p++) {
      acquire(&p->lock);
      if(p->state == RUNNABLE) {
        // Switch to chosen process.  It is the process's job
        // to release its lock and then reacquire it
        // before jumping back to us.
        p->state = RUNNING;
        c->proc = p;
        swtch(&c->context, &p->context);

        // Process is done running for now.
        // It should have changed its p->state before coming back.
        c->proc = 0;

        found = 1;
      }
      release(&p->lock);
    }
#if !defined (LAB_FS)
    if(found == 0) {
      intr_on();
      asm volatile("wfi");
    }
#else
    ;
#endif
  }
}
```

scheduler函数中的swtch(&c->context, &p->context)将当前scheduler执行的寄存快照存储到了cpu的context中，并将要执行的进程的寄存器快照载入到当前cpu中，而sched函数中swtch(&p->context, &mycpu()->context)进行了相反的工作，再次将sheduler加载到CPU上运行

调用sched时,当前CPU必须获得当前进程的锁,且当前CPU上的push_off的层数必须为1,当前进程的的状态不能为正在运行，且不能是interruptible，获取当前CPU的intena状态，并要在完成swtch之后回复

```assembly
.globl swtch
swtch:
        sd ra, 0(a0)
        sd sp, 8(a0)
        sd s0, 16(a0)
        sd s1, 24(a0)
        sd s2, 32(a0)
        sd s3, 40(a0)
        sd s4, 48(a0)
        sd s5, 56(a0)
        sd s6, 64(a0)
        sd s7, 72(a0)
        sd s8, 80(a0)
        sd s9, 88(a0)
        sd s10, 96(a0)
        sd s11, 104(a0)

        ld ra, 0(a1)
        ld sp, 8(a1)
        ld s0, 16(a1)
        ld s1, 24(a1)
        ld s2, 32(a1)
        ld s3, 40(a1)
        ld s4, 48(a1)
        ld s5, 56(a1)
        ld s6, 64(a1)
        ld s7, 72(a1)
        ld s8, 80(a1)
        ld s9, 88(a1)
        ld s10, 96(a1)
        ld s11, 104(a1)
        
        ret
```

swtch函数将当前寄存器的快照保存到a0所指向地址(&p->context),并载入a1所指向地址的寄存器快照(&mycpu()->context),最后返回，此时CPU执行的已经是新的进程
swtch performs the saves and restores for a kernel thread switch. When it is time for a process to give up the CPU, the process’s kernel thread calls swtch to save its own context and return to the scheduler context.

从上面可以看出从一个线程切换到另一个线程包含以下操作(懒得翻译了，很简单)
a user-kernel transition (system call or interrupt) to the old process’s kernel thread, a context switch to the current CPU’s scheduler thread, a context switch to a new process’s kernel thread, and a trap return to the user-level process

### wait, exit, kill

这一部分代码比较冗长，也不难看懂，就是涉及一个遍历proc数组的过程，不放了，直接看源码即可

## My Q&A

**1. sched和interrupt相关的问题，为什么第二段中要disable interrupt，如果不这么做会怎么样？结合进程调度&切换来解答一下，理解并解释一下下面这段话**

>The interaction of spinlocks and interrupts raises a potential danger. Suppose sys_sleep holdstickslock , and its CPU is interrupted by a timer interrupt. clockintr would try to acquiretickslock , see it was held, and wait for it to be released. In this situation, tickslock willnever be released: only sys_sleep can release it, but sys_sleep will not continue running untilclockintr returns. So the CPU will deadlock, and any code that needs either lock will also freeze.

>To avoid this situation, if a spinlock is used by an interrupt handler, a CPU must never hold that lock with interrupts enabled. Xv6 is more conservative: when a CPU acquires any lock, xv6always disables interrupts on that CPU. Interrupts may still occur on other CPUs, so an interrupt’sacquire can wait for a thread to release a spinlock; just not on the same CPU.

>Some xv6 spinlocks protect data that is used by both threads and interrupt handlers. For example,the clockintr timer interrupt handler might increment ticks (kernel/trap.c:163) at about the sametime that a kernel thread reads ticks in sys_sleep (kernel/sysproc.c:64) . The lock tickslockserializes the two accesses.

  可以考虑这种特殊情况：一个进程获取了锁但还没有释放且enable 了 interrupt，在这个进程获得的时间片结束时候的timeinterrupt可以打断当前进程，但timeinterrupt handler中需要获取的那个锁已经被当前进程占有，锁永远不能获取。于是形成了死锁，就会不断在time interrupt上产生time interrupt？从第二段话里面也可以看到 To avoid this situation, if a spinlock is used by an interrupt handler, a CPU must never hold that lock with interrupts enabled. 如果锁被可能被interrupt handler acquire，cpu就永远不能在 interrupt enable的情况下持有这个锁。而XV-6使用了一种更为保守的做法 when a CPU acquires any lock, xv6always disables interrupts on that CPU

**2. 为什么sleeplock不需要打开/关闭inter?**

  因为尝试获取sleeplock的线程不会阻塞&busy waiting，而是阻塞，将自己的状态改为SLEEPING，并等待其他线程释放sleeplock并将自己的状态变为RUNNABLE

**3. sleep 中这一部分代码：**

```c
if(lk != &p->lock){  //DOC: sleeplock0
  acquire(&p->lock);  //DOC: sleeplock1
  release(lk);
}
```

**获取进程的锁的意义是什么，或者说明一下尝试获取的锁就是进程锁的情况怎么理解，怎么才会出现？**

  acquire进程的pcb上的spinlock的原因是因为之后的代码要修改pcb中的p->chan = chan，p->state数据，很显然，为了保护临界区。不过有意思的一点是这一部分代码立刻释放了sleeplock上的spinlock，就像上面说的，sleeplock的spinlock是为了保护sleeplock结构中的locked等临界区变量，这样做减少了sleeplock中的阻塞。

  而尝试获取的锁就是进程锁这种情况，我认为就是没有通过自旋锁，而是通过void *chan将一个/多个线程设置为sleeping，可以在之后一些其他同步情况下使用。

**4. sched()中要求且当前CPU上的push_off的层数必须为1(?why),当前进程的的状态不能为正在运行，且不能是interruptible，获取当前CPU的intena状态，并要在完成swtch之后回复，这一段的用意是什么？**

```
// Switch to scheduler.  Must hold only p->lock
// and have changed proc->state. Saves and restores
// intena because intena is a property of this
// kernel thread, not this CPU. It should
// be proc->intena and proc->noff, but that would
// break in the few places where a lock is held but
// there's no process.
```

  上面注释中，intena is a property of this kernel thread, not this CPU.intena是内核态线程的属性，不是用户态线程的，肯定不能在用户态disable interrupe，那样也太不安全了。同理，上面检查的那些参数也是属于内核态的，也可以结合来理解，内核态的代码由设计者设计，希望保证了调用的合理性。所以如果调用sched时不合理，就说明内核代码设计存在问题，上面做的就是直接panic
